{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing ImageDataGenerator from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm_watson_machine_learning in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.257)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.26.0)\n",
      "Requirement already satisfied: pandas<1.5.0,>=0.24.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.3.4)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.8.9)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (21.3)\n",
      "Requirement already satisfied: ibm-cos-sdk==2.11.* in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.11.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (4.8.2)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.3.3)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.26.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2022.9.24)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from importlib-metadata->ibm_watson_machine_learning) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->ibm_watson_machine_learning) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ibm_watson_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_watson_machine_learning\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentilas = {\n",
    "                   \"url\":\"https://us-south.ml.cloud.ibm.com\",\n",
    "                   \"apikey\":\"hxe6koyIaU12_be6Qw-sQ8omzOrg9czDp9Ep11YppBs6\"\n",
    "}\n",
    "client = APIClient(wml_credentilas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space UID = 2bae4b0b-57cd-4fd3-89ef-5fc4a44867a5\n"
     ]
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client, 'Forestrecognition')\n",
    "print(\"Space UID = \" + space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='bhtzDKXCeJ2Rko2lY0HoTEVMuI1P_Ds2Zmv5EwCoOnyp',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'cnnmodel-donotdelete-pr-5jfgh2lpsrolaa'\n",
    "object_key = 'Dataset-20221116T055616Z-001.zip'\n",
    "\n",
    "streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ImageDataGenerator functionality to train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory('/home/wsuser/work/Dataset/train_set',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ImageDataGenerator functionality to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory('/home/wsuser/work/Dataset/test_set',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Model Building Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to define the linear Initialisation import sequential\n",
    "from keras.models import Sequential\n",
    "#to add layers import Dense\n",
    "from keras.layers import Dense\n",
    "#to create Convolutional kernel import convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "#import Maxpooling layer \n",
    "from keras.layers import MaxPooling2D\n",
    "#import flatten layer\n",
    "from keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "#add maxpooling layers\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#add faltten layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add hidden layers\n",
    "model.add(Dense(150,activation='relu'))\n",
    "#add output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configuring the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 1.0992 - accuracy: 0.6353 - val_loss: 0.3017 - val_accuracy: 0.8926\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.3195 - accuracy: 0.8463 - val_loss: 0.1315 - val_accuracy: 0.9421\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.2219 - accuracy: 0.8968 - val_loss: 0.1086 - val_accuracy: 0.9587\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1939 - accuracy: 0.9243 - val_loss: 0.0904 - val_accuracy: 0.9752\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.1744 - accuracy: 0.9106 - val_loss: 0.0827 - val_accuracy: 0.9752\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1711 - accuracy: 0.9220 - val_loss: 0.0847 - val_accuracy: 0.9669\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1884 - accuracy: 0.9151 - val_loss: 0.1547 - val_accuracy: 0.9174\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1679 - accuracy: 0.9243 - val_loss: 0.0966 - val_accuracy: 0.9504\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1589 - accuracy: 0.9358 - val_loss: 0.0740 - val_accuracy: 0.9752\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.1516 - accuracy: 0.9312 - val_loss: 0.0544 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cd1680ca0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"forest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load model from keras.model\n",
    "from keras.models import load_model\n",
    "#import image from keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import cv2\n",
    "#load the saved model\n",
    "model=load_model(\"forest.h5\")\n",
    "img=image.load_img('/home/wsuser/work/Dataset/test_set/with fire/with fire (9).jpg')\n",
    "x=image.img_to_array(img)\n",
    "res=cv2.resize(x,dsize=(64,64),interpolation=cv2.INTER_CUBIC)\n",
    "#expand the image shape\n",
    "x=np.expand_dims(res,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(x)\n",
    "pred = int(pred[0][0])\n",
    "pred\n",
    "int(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest fire\n"
     ]
    }
   ],
   "source": [
    "if pred==1:\n",
    "  print('Forest fire')\n",
    "elif pred==0:\n",
    "  print('No Fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open cv for video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twilio\n",
      "  Downloading twilio-7.15.3-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from twilio) (2021.3)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from twilio) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from twilio) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (3.3)\n",
      "Installing collected packages: twilio\n",
      "Successfully installed twilio-7.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7037 sha256=0a843383e171bb37fde4f55b1c7a94c34b2f9b28a6ac76c864c10a469fac6b53\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/ba/39/54/c8f7ff9a88a644d3c58b4dec802d90b79a2e0fb2a6b884bf82\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n"
     ]
    }
   ],
   "source": [
    "from logging import WARNING\n",
    "#import opencv library\n",
    "import cv2\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import image function from keras\n",
    "from keras.preprocessing import image\n",
    "#import load_model from keras\n",
    "from keras.models import load_model\n",
    "#import client from twilio API\n",
    "from twilio.rest import Client\n",
    "#import playsound package\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending Alert Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest fire\n",
      "SM9f80d788df7b59989488039a4e18a0f1\n",
      "Fire detected\n",
      "SMS Sent!\n"
     ]
    }
   ],
   "source": [
    "from twilio.rest import Client\n",
    "from playsound import playsound\n",
    "if pred==1:\n",
    "  print('Forest fire')\n",
    "  account_sid='ACc0b32842aa3060ee6f4b2bfa1116247f'\n",
    "  auth_token='c6a97bddc96eaf4803622bd76e8a96ff'\n",
    "  client=Client(account_sid,auth_token)\n",
    "  message=client.messages \\\n",
    "  .create(\n",
    "      body='forest fire is detected,stay alert',\n",
    "      #use twilio free number\n",
    "      from_='+14793974371',\n",
    "      #to number\n",
    "      to='+919025496556')\n",
    "  print(message.sid)\n",
    "  print(\"Fire detected\")\n",
    "  print(\"SMS Sent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
